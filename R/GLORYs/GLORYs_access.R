#####
## GLORYs Data collection and processing
#####
library(sf)
library(raster)
library(ncdf4)
# install.packages("remotes")
# remotes::install_github("markpayneatwork/RCMEMS")
library(RCMEMS)
library(gmRi)
library(tidyverse)
library(lubridate)
library(here)
library(devtools)

# Sourcing a few functions from SDM workflow and the TargetsSDM functions
devtools::source_url("https://raw.githubusercontent.com/aallyn/TargetsSDM/main/R/combo_functions.R")
devtools::source_url("https://raw.githubusercontent.com/aallyn/TargetsSDM/main/R/vast_functions.R")
devtools::source_url("https://raw.githubusercontent.com/aallyn/TargetsSDM/main/R/enhance_r_funcs.R")
devtools::source_url("https://raw.githubusercontent.com/aallyn/TargetsSDM/main/R/SDM_PredValidation_Functions.R")

# Eval?
eval_use<- FALSE

# Rather than extracting ALL of the GLORYs data, I am going to subset things spatially. We could also further subset things temporally, but in this case, I am interested in all the monthly available data from 1993 to present. 

# Spatial extent shapefile
extent_shp<- st_read(here::here("data/supporting/region_shapefile/full_survey_region.shp"))
extent_shp <- st_read(str_c(cs_path("res", "Shapefiles/nmfs_trawl_regions"), "nmfs_trawl_gulf_of_maine.geojson"))

# Grab the extent to use later on
extent_shp <- st_bbox(extent_shp)

# Getting our temporal subset information. Again, here I want all month-years, but this could be reduced. 
min_year<- 2019
max_year<- 2019
date_range<- base::expand.grid(min_year:max_year, 1:12) %>% 
  dplyr::rename(year = Var1, month = Var2) %>% 
  arrange(year, month) %>% 
  mutate(year_mon = paste0(year,"-",month)) %>% 
  dplyr::select(year_mon)

# Download function -- this was modified slightly from https://theoceancode.netlify.app/post/dl_env_data_r/
download_GLORYS <- function(date_choice, extent_bbox = extent_shp, out_dir_use = "/Users/aallyn/Library/CloudStorage/Box-Box/RES_Data/GLORYs/DFO_NEFSC_Domain_Monthly/"){
  
  if(FALSE){
    date_choice<- date_range$year_mon[1]
  }
  
  # The GLORYS script
  # This is a dummy script first generated by using the UI on the CMEMS website
  # No need to change anything here except for the --user and --pwd at the end
  # Please place your CMEMS username and password in those fields
  GLORYS_script <- 'python3 /usr/local/lib/python3.9/site-packages/motuclient.py --motu http://my.cmems-du.eu/motu-web/Motu --service-id GLOBAL_REANALYSIS_PHY_001_030-TDS --product-id global-reanalysis-phy-001-030-monthly --longitude-min -180 --longitude-max 179.9166717529297 --latitude-min -80 --latitude-max 90 --date-min "2018-12-25 12:00:00" --date-max "2018-12-25 12:00:00" --depth-min 0.493 --depth-max 0.4942 --variable thetao --variable bottomT --variable so --variable zos --variable uo --variable vo --variable mlotst --variable siconc --variable sithick --variable usi --variable vsi --out-dir data --out-name test.nc --user aallyn --pwd Maine1985! --config-file $HOME/motuclient_files/config.ini'
  
  # Prep the necessary URL pieces
  date_start <- parse_date(date_choice, format = "%Y-%m")
  # A clever way of finding the end date of any month!
  # I found this on stackoverflow somewhere...
  date_end <- date_start %m+% months(1) - 1
  
  # Set the file name
  file_name <- paste0("GLORYS_", date_choice, ".nc")
  print(file_name)
  
  # Take the chunk of code above and turn it into something useful
  cfg <- parse.CMEMS.script(GLORYS_script, parse.user = T)
  
  # This is where one should make any required changes to the subsetting of the data
  # This is now the magic of the RCMEMS package, which allows us to interface with the Python code as though it were R
  cfg_update <- RCMEMS::update(
    cfg, 
    variable = "thetao --variable bottomT --variable so --variable zos --variable uo --variable vo --variable mlotst --variable siconc --variable sithick --variable usi --variable vsi",
    longitude.min = as.character(extent_bbox$xmin),
    longitude.max = as.character(extent_bbox$xmax),
    latitude.min = as.character(extent_bbox$ymin),
    latitude.max = as.character(extent_bbox$ymax),
    date.min = as.character(date_start),
    date.max = as.character(date_end),
    out.dir = out_dir_use,
    out.name = file_name)
  
  # Download and save the file if needed
  if(file.exists(paste0(out_dir_use, file_name))){
    return()
  } else{
    CMEMS.download(cfg_update)
  }
  Sys.sleep(2) # Give the server a quick breather
}


# Run function looping over date range
for(i in seq_along(date_range$year_mon)){
  download_GLORYS(
    date_choice = date_range$year_mon[i], 
    extent_bbox = extent_shp, 
    out_dir_use = here::here("local_data/GLORYs/"))
  print(paste0(date_range$year_mon[i], " is done!"))
}

date_range %>% map(year_mon, download_GLORYS)




# Vector of variables we are interested in getting. Check netcdf file to see other potential available variables.
variables_all<- c("thetao", "bottomT", "so")

# Are these already processed or do we need to run the function?
glorys_extract<- any(!file.exists(c(paste0(gmRi::research_access_paths()$res, "GLORYs/DFO_NEFSC_Domain_Monthly/SST.grd"), paste0(gmRi::research_access_paths()$res, "GLORYs/DFO_NEFSC_Domain_Monthly/BottomTemp.grd"), paste0(gmRi::research_access_paths()$res, "GLORYs/DFO_NEFSC_Domain/Salinity.grd"))))

# Which is missing -- update this
variables_all_get<- c("thetao", "bottomT", "so")

if(glorys_extract){
  # Use plyr::l_ply to apply function in parallel
  plyr::l_ply(date_range$year_mon, .fun = download_GLORYS, .parallel = F)
  
  # Loop through and process...
  all_glorys_files<- list.files(paste("/Users/aallyn/Library/CloudStorage/Box-Box/RES_Data/GLORYs/DFO_NEFSC_Domain_Monthly/", sep = ""), full.names = TRUE)
  
  for(h in seq_along(variables_all_get)){
    # Empty raster stack to start
    glorys_stack<- raster::stack()
    crs(glorys_stack)<- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
    
    # Loop over variables
    variable_get<- variables_all_get[h]
    variable_name_nice<- switch(variable_get,
                                "so" = "Salinity",
                                "bottomT" = "BottomTemp",
                                "thetao" = "SST")
    
    for(i in seq_along(all_glorys_files)){
      # Loop over time steps
      t<- nc_open(all_glorys_files[[i]])
      lon_nc<- ncvar_get(t, varid = "longitude")
      nlons<- dim(lon_nc)
      lat_nc<- ncvar_get(t, varid = "latitude")
      nlats<- dim(lat_nc)
      
      # Extract available dates from netCDF file
      times<- ncvar_get(t, var = "time")
      
      # Make times a little bit easier to handle
      dates_full<- as.Date(as.POSIXct("1950-01-01 00:00:00") + as.difftime(times,units="hours"), format = "%Y-%m-%d")
      
      # Run ncvar_get, adjusting order of start and count as needed
      temp<- ncvar_get(t, varid = variable_get)
      
      # Moving from the array format of temp to a raster stack
      rast_out<- fix_raster(temp, lons.use = lon_nc, lats.use = lat_nc, x.min.use = 1, x.max.use = nlons, y.min.use = 1, y.max.use = nlats)
      names(rast_out)<- dates_full
      
      # Store it
      glorys_stack<- raster::stack(glorys_stack, rast_out)
    }
    
    # Write out compiled raster stack
    crs(glorys_stack)<- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
    writeRaster(glorys_stack, paste0("/Users/aallyn/Library/CloudStorage/Box-Box/RES_Data/GLORYs/DFO_NEFSC_Domain_Monthly/", variable_name_nice, ".grd"), overwrite = TRUE)
  }
}